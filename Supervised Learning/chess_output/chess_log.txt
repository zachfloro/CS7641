DECISION TREE RESULTS
Training Set 1:
Decision Tree training time: 0.6403951644897461
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 0.88
In sample precision for Decision Tree: 0.8759302325581396
In sample recall for Decision Tree: 0.88
Decision Tree insample query time: 0.0019583702087402344
Out of sample accuracy for Decision Tree: 0.5702416918429003
Out of sample precision for Decision Tree: 0.5717561197245861
Out of sample recall for Decision Tree: 0.5702416918429003
Decision Tree out of sample query time: 0.09377741813659668
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
Decision Tree training time: 3.8886003494262695
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=4,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 0.918
In sample precision for Decision Tree: 0.9208224616727234
In sample recall for Decision Tree: 0.918
Decision Tree insample query time: 0.01495981216430664
Out of sample accuracy for Decision Tree: 0.6673716012084592
Out of sample precision for Decision Tree: 0.662684722667074
Out of sample recall for Decision Tree: 0.6673716012084592
Decision Tree out of sample query time: 0.09649848937988281
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
Decision Tree training time: 9.651793479919434
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 0.9072
In sample precision for Decision Tree: 0.9084412009579217
In sample recall for Decision Tree: 0.9072
Decision Tree insample query time: 0.03490614891052246
Out of sample accuracy for Decision Tree: 0.7199395770392749
Out of sample precision for Decision Tree: 0.7148031233022607
Out of sample recall for Decision Tree: 0.7199395770392749
Decision Tree out of sample query time: 0.0937497615814209
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
Decision Tree training time: 19.71267604827881
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 0.8816
In sample precision for Decision Tree: 0.8823335911073978
In sample recall for Decision Tree: 0.8816
Decision Tree insample query time: 0.0738060474395752
Out of sample accuracy for Decision Tree: 0.7314199395770393
Out of sample precision for Decision Tree: 0.7232763457516678
Out of sample recall for Decision Tree: 0.7314199395770393
Decision Tree out of sample query time: 0.09175395965576172
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
Decision Tree training time: 48.99062752723694
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 0.8572
In sample precision for Decision Tree: 0.8594997711225999
In sample recall for Decision Tree: 0.8572
Decision Tree insample query time: 0.1406242847442627
Out of sample accuracy for Decision Tree: 0.7509063444108761
Out of sample precision for Decision Tree: 0.7425059182546584
Out of sample recall for Decision Tree: 0.7509063444108761
Decision Tree out of sample query time: 0.09474658966064453
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 6:
Decision Tree training time: 94.84072923660278
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=3,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 0.8480428635213574
In sample precision for Decision Tree: 0.8494160137595548
In sample recall for Decision Tree: 0.8480428635213574
Decision Tree insample query time: 0.36801624298095703
Out of sample accuracy for Decision Tree: 0.7584592145015105
Out of sample precision for Decision Tree: 0.7494321658132401
Out of sample recall for Decision Tree: 0.7584592145015105
Decision Tree out of sample query time: 0.18450689315795898
END OF ITERATION
----------------------------------------------------------------------------------
DECISION TREE W/ BOOSTING RESULTS
Training Set 1:
Boosted Decision Tree training time: 9.13028335571289
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=5,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=10,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.05186128616333008
Out of sample accuracy for Boosted Decision Tree: 0.6311178247734139
Out of sample precision for Boosted Decision Tree: 0.6192771000623167
Out of sample recall for Boosted Decision Tree: 0.6311178247734139
Boosted Decision Tree out of sample query time: 2.8962697982788086
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
