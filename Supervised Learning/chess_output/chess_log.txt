DECISION TREE RESULTS
Training Set 1:
Decision Tree training time: 0.6403951644897461
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 0.88
In sample precision for Decision Tree: 0.8759302325581396
In sample recall for Decision Tree: 0.88
Decision Tree insample query time: 0.0019583702087402344
Out of sample accuracy for Decision Tree: 0.5702416918429003
Out of sample precision for Decision Tree: 0.5717561197245861
Out of sample recall for Decision Tree: 0.5702416918429003
Decision Tree out of sample query time: 0.09377741813659668
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
Decision Tree training time: 3.8886003494262695
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=4,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 0.918
In sample precision for Decision Tree: 0.9208224616727234
In sample recall for Decision Tree: 0.918
Decision Tree insample query time: 0.01495981216430664
Out of sample accuracy for Decision Tree: 0.6673716012084592
Out of sample precision for Decision Tree: 0.662684722667074
Out of sample recall for Decision Tree: 0.6673716012084592
Decision Tree out of sample query time: 0.09649848937988281
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
Decision Tree training time: 9.651793479919434
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 0.9072
In sample precision for Decision Tree: 0.9084412009579217
In sample recall for Decision Tree: 0.9072
Decision Tree insample query time: 0.03490614891052246
Out of sample accuracy for Decision Tree: 0.7199395770392749
Out of sample precision for Decision Tree: 0.7148031233022607
Out of sample recall for Decision Tree: 0.7199395770392749
Decision Tree out of sample query time: 0.0937497615814209
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
Decision Tree training time: 19.71267604827881
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 0.8816
In sample precision for Decision Tree: 0.8823335911073978
In sample recall for Decision Tree: 0.8816
Decision Tree insample query time: 0.0738060474395752
Out of sample accuracy for Decision Tree: 0.7314199395770393
Out of sample precision for Decision Tree: 0.7232763457516678
Out of sample recall for Decision Tree: 0.7314199395770393
Decision Tree out of sample query time: 0.09175395965576172
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
Decision Tree training time: 48.99062752723694
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 0.8572
In sample precision for Decision Tree: 0.8594997711225999
In sample recall for Decision Tree: 0.8572
Decision Tree insample query time: 0.1406242847442627
Out of sample accuracy for Decision Tree: 0.7509063444108761
Out of sample precision for Decision Tree: 0.7425059182546584
Out of sample recall for Decision Tree: 0.7509063444108761
Decision Tree out of sample query time: 0.09474658966064453
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 6:
Decision Tree training time: 94.84072923660278
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=3,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 0.8480428635213574
In sample precision for Decision Tree: 0.8494160137595548
In sample recall for Decision Tree: 0.8480428635213574
Decision Tree insample query time: 0.36801624298095703
Out of sample accuracy for Decision Tree: 0.7584592145015105
Out of sample precision for Decision Tree: 0.7494321658132401
Out of sample recall for Decision Tree: 0.7584592145015105
Decision Tree out of sample query time: 0.18450689315795898
END OF ITERATION
----------------------------------------------------------------------------------
DECISION TREE W/ BOOSTING RESULTS
Training Set 1:
Boosted Decision Tree training time: 9.13028335571289
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=5,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=10,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.05186128616333008
Out of sample accuracy for Boosted Decision Tree: 0.6311178247734139
Out of sample precision for Boosted Decision Tree: 0.6192771000623167
Out of sample recall for Boosted Decision Tree: 0.6311178247734139
Boosted Decision Tree out of sample query time: 2.8962697982788086
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
Boosted Decision Tree training time: 78.04902672767639
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=10,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=10,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.4408233165740967
Out of sample accuracy for Boosted Decision Tree: 0.7253776435045317
Out of sample precision for Boosted Decision Tree: 0.7204194399632032
Out of sample recall for Boosted Decision Tree: 0.7253776435045317
Boosted Decision Tree out of sample query time: 2.8585288524627686
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
Boosted Decision Tree training time: 204.47348642349243
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=25,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=15,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 1.0860974788665771
Out of sample accuracy for Boosted Decision Tree: 0.7558912386706949
Out of sample precision for Boosted Decision Tree: 0.7540970127041937
Out of sample recall for Boosted Decision Tree: 0.7558912386706949
Boosted Decision Tree out of sample query time: 2.884801149368286
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
Boosted Decision Tree training time: 437.18095898628235
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=50,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=10,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 2.183763265609741
Out of sample accuracy for Boosted Decision Tree: 0.7661631419939577
Out of sample precision for Boosted Decision Tree: 0.7605408423421784
Out of sample recall for Boosted Decision Tree: 0.7661631419939577
Boosted Decision Tree out of sample query time: 2.8920469284057617
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
Boosted Decision Tree training time: 937.8287332057953
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=50,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=10,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 4.414010524749756
Out of sample accuracy for Boosted Decision Tree: 0.7753776435045318
Out of sample precision for Boosted Decision Tree: 0.7729312648433762
Out of sample recall for Boosted Decision Tree: 0.7753776435045318
Boosted Decision Tree out of sample query time: 2.9013309478759766
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 6:
Boosted Decision Tree training time: 1311.3654198646545
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=50,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=10,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 6.129483938217163
Out of sample accuracy for Boosted Decision Tree: 0.7821752265861027
Out of sample precision for Boosted Decision Tree: 0.7774667019423785
Out of sample recall for Boosted Decision Tree: 0.7821752265861027
Boosted Decision Tree out of sample query time: 2.8822202682495117
END OF ITERATION
----------------------------------------------------------------------------------
K NEAREST NEIGHBORS RESULTS
Training Set 1:
KNN training time: 0.13898468017578125
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=20, p=2,
                     weights='distance')
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.005060672760009766
Out of sample accuracy for KNN: 0.6089123867069487
Out of sample precision for KNN: 0.5788094950934043
Out of sample recall for KNN: 0.6089123867069487
KNN out of sample query time: 0.33092355728149414
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
KNN training time: 2.9099361896514893
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=20, p=2,
                     weights='uniform')
In sample accuracy for KNN: 0.694
In sample precision for KNN: 0.6673521671826624
In sample recall for KNN: 0.694
KNN insample query time: 0.522712230682373
Out of sample accuracy for KNN: 0.6249244712990937
Out of sample precision for KNN: 0.6106724192057417
Out of sample recall for KNN: 0.6249244712990937
KNN out of sample query time: 3.8710556030273438
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
KNN training time: 15.678296089172363
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=20, p=2,
                     weights='distance')
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 2.82100772857666
Out of sample accuracy for KNN: 0.645619335347432
Out of sample precision for KNN: 0.6621088804724201
Out of sample recall for KNN: 0.645619335347432
KNN out of sample query time: 7.542051315307617
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
KNN training time: 53.11440968513489
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=20, p=2,
                     weights='distance')
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 10.026546716690063
Out of sample accuracy for KNN: 0.6483383685800604
Out of sample precision for KNN: 0.6643466154605284
Out of sample recall for KNN: 0.6483383685800604
KNN out of sample query time: 13.857147693634033
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
KNN training time: 164.2701451778412
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=20, p=2,
                     weights='distance')
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 34.67335891723633
Out of sample accuracy for KNN: 0.6735649546827794
Out of sample precision for KNN: 0.6838612667043321
Out of sample recall for KNN: 0.6735649546827794
KNN out of sample query time: 22.957765340805054
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 6:
KNN training time: 268.8363618850708
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=20, p=2,
                     weights='distance')
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 53.16973400115967
Out of sample accuracy for KNN: 0.6867069486404834
Out of sample precision for KNN: 0.6929000417481607
Out of sample recall for KNN: 0.6867069486404834
KNN out of sample query time: 27.13256335258484
END OF ITERATION
----------------------------------------------------------------------------------
SUPPORT VECTOR MACHINE RESULTS
Training Set 1:
SVC training time: 0.10768508911132812
Best Classifier Chosen: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=13, tol=0.0001,
          verbose=0)
In sample accuracy for SVC: 0.95
In sample precision for SVC: 0.9506442705936493
In sample recall for SVC: 0.95
SVC insample query time: 0.003987312316894531
Out of sample accuracy for SVC: 0.6466767371601209
Out of sample precision for SVC: 0.6320437531945031
Out of sample recall for SVC: 0.6466767371601209
SVC out of sample query time: 0.010714054107666016
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
SVC training time: 0.8053982257843018
Best Classifier Chosen: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=13, tol=0.01,
          verbose=0)
In sample accuracy for SVC: 0.842
In sample precision for SVC: 0.8413581481307038
In sample recall for SVC: 0.842
SVC insample query time: 0.002992391586303711
Out of sample accuracy for SVC: 0.7512084592145015
Out of sample precision for SVC: 0.7322570241291331
Out of sample recall for SVC: 0.7512084592145015
SVC out of sample query time: 0.005984306335449219
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
SVC training time: 1.641144037246704
Best Classifier Chosen: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=13, tol=0.0001,
          verbose=0)
In sample accuracy for SVC: 0.824
In sample precision for SVC: 0.8286706470865706
In sample recall for SVC: 0.824
SVC insample query time: 0.007982254028320312
Out of sample accuracy for SVC: 0.7626888217522658
Out of sample precision for SVC: 0.7374915041719176
Out of sample recall for SVC: 0.7626888217522658
SVC out of sample query time: 0.004981040954589844
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
SVC training time: 3.036119222640991
Best Classifier Chosen: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.01, verbose=0)
In sample accuracy for SVC: 0.8026
In sample precision for SVC: 0.8049938279589643
In sample recall for SVC: 0.8026
SVC insample query time: 0.012968063354492188
Out of sample accuracy for SVC: 0.7735649546827794
Out of sample precision for SVC: 0.7424628167316585
Out of sample recall for SVC: 0.7735649546827794
SVC out of sample query time: 0.004991292953491211
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
SVC training time: 5.87903356552124
Best Classifier Chosen: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
In sample accuracy for SVC: 0.8008
In sample precision for SVC: 0.7915757659206767
In sample recall for SVC: 0.8008
SVC insample query time: 0.025963544845581055
Out of sample accuracy for SVC: 0.7785498489425982
Out of sample precision for SVC: 0.7651895720320796
Out of sample recall for SVC: 0.7785498489425982
SVC out of sample query time: 0.004986286163330078
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 6:
SVC training time: 8.002599954605103
Best Classifier Chosen: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.01, verbose=0)
In sample accuracy for SVC: 0.8000446495014139
In sample precision for SVC: 0.8015748427937955
In sample recall for SVC: 0.8000446495014139
SVC insample query time: 0.009006261825561523
Out of sample accuracy for SVC: 0.7799093655589124
Out of sample precision for SVC: 0.7905807655339607
Out of sample recall for SVC: 0.7799093655589124
SVC out of sample query time: 0.004987239837646484
END OF ITERATION
----------------------------------------------------------------------------------
NEURAL NETWORK RESULTS
Training Set 1:
NEURAL NETWORK RESULTS
Training Set 1:
NN training time: 11.554229259490967
NEURAL NETWORK RESULTS
Training Set 1:
NN training time: 11.410328388214111
In sample accuracy for nn: 0.48
In sample precision for NN: 0.4283050847457627
In sample recall for NN: 0.48
NN insample query time: 0.0009965896606445312
NEURAL NETWORK RESULTS
Training Set 1:
NN training time: 11.01409912109375
In sample accuracy for nn: 0.48
In sample precision for NN: 0.4283050847457627
In sample recall for NN: 0.48
NN insample query time: 0.0
Out of sample accuracy for NN: 0.3122356495468278
Out of sample precision for NN: 0.3239138971520204
Out of sample recall for NN: 0.3122356495468278
SVC out of sample query time: 0.011967897415161133
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
NN training time: 47.911113023757935
In sample accuracy for nn: 0.429
In sample precision for NN: 0.4252221227689428
In sample recall for NN: 0.429
NN insample query time: 0.0019948482513427734
Out of sample accuracy for NN: 0.34003021148036255
Out of sample precision for NN: 0.365281327918356
Out of sample recall for NN: 0.34003021148036255
SVC out of sample query time: 0.015961647033691406
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
NN training time: 136.02347874641418
In sample accuracy for nn: 0.4336
In sample precision for NN: 0.3985559398028344
In sample recall for NN: 0.4336
NN insample query time: 0.005982875823974609
Out of sample accuracy for NN: 0.3779456193353474
Out of sample precision for NN: 0.3494448118901557
Out of sample recall for NN: 0.3779456193353474
SVC out of sample query time: 0.014963626861572266
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
NN training time: 272.3504524230957
In sample accuracy for nn: 0.386
In sample precision for NN: 0.40714799181206957
In sample recall for NN: 0.386
NN insample query time: 0.010996341705322266
Out of sample accuracy for NN: 0.3501510574018127
Out of sample precision for NN: 0.37068881192002634
Out of sample recall for NN: 0.3501510574018127
SVC out of sample query time: 0.014008045196533203
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
NN training time: 526.2663900852203
In sample accuracy for nn: 0.3802
In sample precision for NN: 0.39587092289672227
In sample recall for NN: 0.3802
NN insample query time: 0.021941423416137695
Out of sample accuracy for NN: 0.35196374622356497
Out of sample precision for NN: 0.3717369226944346
Out of sample recall for NN: 0.35196374622356497
SVC out of sample query time: 0.013962984085083008
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 6:
NN training time: 677.8776199817657
In sample accuracy for nn: 0.31969043012353027
In sample precision for NN: 0.40455349914233846
In sample recall for NN: 0.31969043012353027
NN insample query time: 0.02792525291442871
Out of sample accuracy for NN: 0.3040785498489426
Out of sample precision for NN: 0.395848407626032
Out of sample recall for NN: 0.3040785498489426
SVC out of sample query time: 0.010970354080200195
END OF ITERATION
----------------------------------------------------------------------------------
