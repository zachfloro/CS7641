DECISION TREE RESULTS
Training Set 1:
Decision Tree training time: 0.24646782875061035
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=10,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 0.94
In sample precision for Decision Tree: 1.0
In sample recall for Decision Tree: 0.8695652173913043
Decision Tree insample query time: 0.0009968280792236328
Out of sample accuracy for Decision Tree: 0.696969696969697
Out of sample precision for Decision Tree: 0.34626865671641793
Out of sample recall for Decision Tree: 0.5036179450072359
Decision Tree out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
Decision Tree training time: 0.3700129985809326
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=10,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 0.904
In sample precision for Decision Tree: 0.9297520661157025
In sample recall for Decision Tree: 0.87890625
Decision Tree insample query time: 0.0
Out of sample accuracy for Decision Tree: 0.7387878787878788
Out of sample precision for Decision Tree: 0.41492537313432837
Out of sample recall for Decision Tree: 0.6034732272069464
Decision Tree out of sample query time: 0.0009872913360595703
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
Decision Tree training time: 0.5744667053222656
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 1.0
In sample precision for Decision Tree: 1.0
In sample recall for Decision Tree: 1.0
Decision Tree insample query time: 0.0009989738464355469
Out of sample accuracy for Decision Tree: 0.7193939393939394
Out of sample precision for Decision Tree: 0.3894637817497648
Out of sample recall for Decision Tree: 0.5991316931982634
Decision Tree out of sample query time: 0.0009987354278564453
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
Decision Tree training time: 0.9236404895782471
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 1.0
In sample precision for Decision Tree: 1.0
In sample recall for Decision Tree: 1.0
Decision Tree insample query time: 0.0009980201721191406
Out of sample accuracy for Decision Tree: 0.7548484848484849
Out of sample precision for Decision Tree: 0.43655913978494626
Out of sample recall for Decision Tree: 0.5875542691751086
Decision Tree out of sample query time: 0.000997781753540039
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
Decision Tree training time: 1.6914820671081543
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 1.0
In sample precision for Decision Tree: 1.0
In sample recall for Decision Tree: 1.0
Decision Tree insample query time: 0.0029935836791992188
Out of sample accuracy for Decision Tree: 0.8145454545454546
Out of sample precision for Decision Tree: 0.5620094191522763
Out of sample recall for Decision Tree: 0.5180897250361794
Decision Tree out of sample query time: 0.000997304916381836
END OF ITERATION
----------------------------------------------------------------------------------
DECISION TREE W/ BOOSTING RESULTS
Training Set 1:
Boosted Decision Tree training time: 1.6188087463378906
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=5,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=10,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.003988027572631836
Out of sample accuracy for Boosted Decision Tree: 0.7254545454545455
Out of sample precision for Boosted Decision Tree: 0.3923923923923924
Out of sample recall for Boosted Decision Tree: 0.5672937771345875
Boosted Decision Tree out of sample query time: 0.02293872833251953
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
Boosted Decision Tree training time: 4.683341979980469
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=10,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=15,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.010971784591674805
Out of sample accuracy for Boosted Decision Tree: 0.7442424242424243
Out of sample precision for Boosted Decision Tree: 0.4240317775571003
Out of sample recall for Boosted Decision Tree: 0.61794500723589
Boosted Decision Tree out of sample query time: 0.026927947998046875
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
Boosted Decision Tree training time: 10.103471279144287
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=50,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=5,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.022936582565307617
Out of sample accuracy for Boosted Decision Tree: 0.7972727272727272
Out of sample precision for Boosted Decision Tree: 0.5143229166666666
Out of sample recall for Boosted Decision Tree: 0.5716353111432706
Boosted Decision Tree out of sample query time: 0.029920339584350586
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
Boosted Decision Tree training time: 19.178627252578735
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=25,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=10,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.04188799858093262
Out of sample accuracy for Boosted Decision Tree: 0.8275757575757576
Out of sample precision for Boosted Decision Tree: 0.6030405405405406
Out of sample recall for Boosted Decision Tree: 0.516642547033285
Boosted Decision Tree out of sample query time: 0.03091740608215332
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
Boosted Decision Tree training time: 39.52348709106445
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=25,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=10,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.08776497840881348
Out of sample accuracy for Boosted Decision Tree: 0.8406060606060606
Out of sample precision for Boosted Decision Tree: 0.7337110481586402
Out of sample recall for Boosted Decision Tree: 0.3748191027496382
Boosted Decision Tree out of sample query time: 0.031914710998535156
END OF ITERATION
----------------------------------------------------------------------------------
K NEAREST NEIGHBORS RESULTS
Training Set 1:
KNN training time: 0.06382989883422852
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,
                     weights='distance')
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.00099945068359375
Out of sample accuracy for KNN: 0.6478787878787878
Out of sample precision for KNN: 0.3155833985904464
Out of sample recall for KNN: 0.5832127351664255
KNN out of sample query time: 0.007993221282958984
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
KNN training time: 0.21654605865478516
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,
                     weights='uniform')
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.02094411849975586
Out of sample accuracy for KNN: 0.6509090909090909
Out of sample precision for KNN: 0.31091058244462677
Out of sample recall for KNN: 0.548480463096961
KNN out of sample query time: 0.07879042625427246
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
KNN training time: 0.5934457778930664
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,
                     weights='uniform')
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.05581855773925781
Out of sample accuracy for KNN: 0.7012121212121212
Out of sample precision for KNN: 0.357487922705314
Out of sample recall for KNN: 0.5354558610709117
KNN out of sample query time: 0.0967416763305664
END OF ITERATION
----------------------------------------------------------------------------------
