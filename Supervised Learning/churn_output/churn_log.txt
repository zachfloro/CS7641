DECISION TREE RESULTS
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=10,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
Cross Validation Results: [0.65913336 0.65913336 0.74561076 0.74561076 0.84833769 0.83974598]
Training Set 1:
Decision Tree training time: 0.000997304916381836
In sample accuracy for Decision Tree: 0.89
In sample precision for Decision Tree: 0.8541666666666666
In sample recall for Decision Tree: 0.9111111111111111
Decision Tree insample query time: 0.0
Out of sample accuracy for Decision Tree: 0.5763636363636364
Out of sample precision for Decision Tree: 0.2729608220937701
Out of sample recall for Decision Tree: 0.6150506512301013
Decision Tree out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
Decision Tree training time: 0.0029916763305664062
In sample accuracy for Decision Tree: 0.904
In sample precision for Decision Tree: 0.8980392156862745
In sample recall for Decision Tree: 0.9123505976095617
Decision Tree insample query time: 0.0009975433349609375
Out of sample accuracy for Decision Tree: 0.7357575757575757
Out of sample precision for Decision Tree: 0.4182475158084914
Out of sample recall for Decision Tree: 0.6700434153400868
Decision Tree out of sample query time: 0.0009970664978027344
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
Decision Tree training time: 0.0069811344146728516
In sample accuracy for Decision Tree: 0.8904
In sample precision for Decision Tree: 0.9034138218151541
In sample recall for Decision Tree: 0.8728881737731295
Decision Tree insample query time: 0.0009980201721191406
Out of sample accuracy for Decision Tree: 0.7778787878787878
Out of sample precision for Decision Tree: 0.47707423580786024
Out of sample recall for Decision Tree: 0.6324167872648335
Decision Tree out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
Decision Tree training time: 0.011967897415161133
In sample accuracy for Decision Tree: 0.8836
In sample precision for Decision Tree: 0.8632414053645636
In sample recall for Decision Tree: 0.9121756487025948
Decision Tree insample query time: 0.000997781753540039
Out of sample accuracy for Decision Tree: 0.7506060606060606
Out of sample precision for Decision Tree: 0.43796992481203006
Out of sample recall for Decision Tree: 0.6743849493487699
Decision Tree out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
Decision Tree training time: 0.025930166244506836
In sample accuracy for Decision Tree: 0.8751400821815465
In sample precision for Decision Tree: 0.8458756672980885
In sample recall for Decision Tree: 0.9174449010085917
Decision Tree insample query time: 0.001995086669921875
Out of sample accuracy for Decision Tree: 0.7648484848484849
Out of sample precision for Decision Tree: 0.45861733203505356
Out of sample recall for Decision Tree: 0.6816208393632417
Decision Tree out of sample query time: 0.000997304916381836
END OF ITERATION
----------------------------------------------------------------------------------
DECISION TREE W/ BOOSTING RESULTS
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=25,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=10,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
Cross Validation Results: [0.94293986 0.9402316  0.93873739 0.9489167  0.94546134 0.94293986
 0.94798282 0.94658199 0.94602167]
Training Set 1:
Boosted Decision Tree training time: 0.036901235580444336
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.004986763000488281
Out of sample accuracy for Boosted Decision Tree: 0.7224242424242424
Out of sample precision for Boosted Decision Tree: 0.38738738738738737
Out of sample recall for Boosted Decision Tree: 0.5600578871201157
Boosted Decision Tree out of sample query time: 0.02293872833251953
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
Boosted Decision Tree training time: 0.16655516624450684
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.010983943939208984
Out of sample accuracy for Boosted Decision Tree: 0.7660606060606061
Out of sample precision for Boosted Decision Tree: 0.45803108808290155
Out of sample recall for Boosted Decision Tree: 0.6396526772793053
Boosted Decision Tree out of sample query time: 0.026928424835205078
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
Boosted Decision Tree training time: 0.40990447998046875
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.02393627166748047
Out of sample accuracy for Boosted Decision Tree: 0.8006060606060607
Out of sample precision for Boosted Decision Tree: 0.5218543046357615
Out of sample recall for Boosted Decision Tree: 0.5701881331403763
Boosted Decision Tree out of sample query time: 0.029920101165771484
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
Boosted Decision Tree training time: 0.8108453750610352
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.04188823699951172
Out of sample accuracy for Boosted Decision Tree: 0.8248484848484848
Out of sample precision for Boosted Decision Tree: 0.6007130124777184
Out of sample recall for Boosted Decision Tree: 0.487698986975398
Boosted Decision Tree out of sample query time: 0.030916929244995117
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
Boosted Decision Tree training time: 1.71195387840271
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.08876252174377441
Out of sample accuracy for Boosted Decision Tree: 0.843030303030303
Out of sample precision for Boosted Decision Tree: 0.7464387464387464
Out of sample recall for Boosted Decision Tree: 0.3791606367583213
Boosted Decision Tree out of sample query time: 0.03390932083129883
