DECISION TREE RESULTS
Best Classifier Chosen: DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
                       max_depth=5, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=20,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
Cross Validation Results: [0.67013096 0.67013096 0.73330646 0.73553583 0.6812998  0.6916977 ]
Training Set 1:
Decision Tree training time: 0.0
In sample accuracy for Decision Tree: 0.77
In sample precision for Decision Tree: 0.41025641025641024
In sample recall for Decision Tree: 1.0
Decision Tree insample query time: 0.0009937286376953125
Out of sample accuracy for Decision Tree: 0.62
Out of sample precision for Decision Tree: 0.2698282910874898
Out of sample recall for Decision Tree: 0.47756874095513746
Decision Tree out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
Decision Tree training time: 0.0029931068420410156
In sample accuracy for Decision Tree: 0.739
In sample precision for Decision Tree: 0.4373522458628842
In sample recall for Decision Tree: 0.8894230769230769
Decision Tree insample query time: 0.0
Out of sample accuracy for Decision Tree: 0.6793939393939394
Out of sample precision for Decision Tree: 0.3647752394988946
Out of sample recall for Decision Tree: 0.7163531114327062
Decision Tree out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
Decision Tree training time: 0.005980968475341797
In sample accuracy for Decision Tree: 0.7948
In sample precision for Decision Tree: 0.4775510204081633
In sample recall for Decision Tree: 0.73125
Decision Tree insample query time: 0.0009975433349609375
Out of sample accuracy for Decision Tree: 0.7887878787878788
Out of sample precision for Decision Tree: 0.49668141592920356
Out of sample recall for Decision Tree: 0.6497829232995659
Decision Tree out of sample query time: 0.0009663105010986328
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
Decision Tree training time: 0.011967897415161133
In sample accuracy for Decision Tree: 0.7936
In sample precision for Decision Tree: 0.48933333333333334
In sample recall for Decision Tree: 0.734
Decision Tree insample query time: 0.0
Out of sample accuracy for Decision Tree: 0.7821212121212121
Out of sample precision for Decision Tree: 0.48544698544698545
Out of sample recall for Decision Tree: 0.6758321273516642
Decision Tree out of sample query time: 0.0009970664978027344
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
Decision Tree training time: 0.013962507247924805
In sample accuracy for Decision Tree: 0.7950746268656717
In sample precision for Decision Tree: 0.49327354260089684
In sample recall for Decision Tree: 0.7355126300148589
Decision Tree insample query time: 0.0009970664978027344
Out of sample accuracy for Decision Tree: 0.7881818181818182
Out of sample precision for Decision Tree: 0.49580712788259956
Out of sample recall for Decision Tree: 0.6845151953690304
Decision Tree out of sample query time: 0.000997304916381836
END OF ITERATION
----------------------------------------------------------------------------------
DECISION TREE W/ BOOSTING RESULTS
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight='balanced',
                                                         criterion='entropy',
                                                         max_depth=10,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=30,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=0.001, n_estimators=50, random_state=13)
Cross Validation Results: [0.36033955 0.36702275 0.45617481 0.40564754 0.55201942 0.51782535
 0.39450228 0.38707283 0.47919174 0.42123283 0.60774128 0.55795258
 0.40193336 0.40119703 0.48885938 0.45987081 0.61591859 0.58394235
 0.41233677 0.40639818 0.407867   0.3677459  0.5037161  0.49553985
 0.34545096 0.35659622 0.3877938  0.36477029 0.54160785 0.50966016
 0.37221127 0.35884322 0.39152285 0.37368176 0.56166948 0.52155771
 0.38336857 0.39451823 0.39374174 0.38704862 0.50222967 0.48885446
 0.3506373  0.3543515  0.40341099 0.36999671 0.53937957 0.50816823
 0.3766667  0.36626884 0.40044034 0.38556827 0.56241297 0.52006412]
Training Set 1:
Boosted Decision Tree training time: 0.042885541915893555
In sample accuracy for Boosted Decision Tree: 0.89
In sample precision for Boosted Decision Tree: 0.5925925925925926
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.003989219665527344
Out of sample accuracy for Boosted Decision Tree: 0.7366666666666667
Out of sample precision for Boosted Decision Tree: 0.34494773519163763
Out of sample recall for Boosted Decision Tree: 0.2865412445730825
Boosted Decision Tree out of sample query time: 0.02094411849975586
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
Boosted Decision Tree training time: 0.18650126457214355
In sample accuracy for Boosted Decision Tree: 0.926
In sample precision for Boosted Decision Tree: 0.7481481481481481
In sample recall for Boosted Decision Tree: 0.9711538461538461
Boosted Decision Tree insample query time: 0.009973526000976562
Out of sample accuracy for Boosted Decision Tree: 0.7881818181818182
Out of sample precision for Boosted Decision Tree: 0.49493670886075947
Out of sample recall for Boosted Decision Tree: 0.5658465991316932
Boosted Decision Tree out of sample query time: 0.023935794830322266
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
Boosted Decision Tree training time: 0.4837181568145752
In sample accuracy for Boosted Decision Tree: 0.9144
In sample precision for Boosted Decision Tree: 0.7071651090342679
In sample recall for Boosted Decision Tree: 0.9458333333333333
Boosted Decision Tree insample query time: 0.021941184997558594
Out of sample accuracy for Boosted Decision Tree: 0.8133333333333334
Out of sample precision for Boosted Decision Tree: 0.5490196078431373
Out of sample recall for Boosted Decision Tree: 0.6078147612156295
Boosted Decision Tree out of sample query time: 0.02792525291442871
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
Boosted Decision Tree training time: 0.9619348049163818
In sample accuracy for Boosted Decision Tree: 0.9176
In sample precision for Boosted Decision Tree: 0.7340764331210191
In sample recall for Boosted Decision Tree: 0.922
Boosted Decision Tree insample query time: 0.036901235580444336
Out of sample accuracy for Boosted Decision Tree: 0.8172727272727273
Out of sample precision for Boosted Decision Tree: 0.5591397849462365
Out of sample recall for Boosted Decision Tree: 0.6020260492040521
Boosted Decision Tree out of sample query time: 0.02792525291442871
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
Boosted Decision Tree training time: 1.305521011352539
In sample accuracy for Boosted Decision Tree: 0.8719402985074627
In sample precision for Boosted Decision Tree: 0.6270833333333333
In sample recall for Boosted Decision Tree: 0.8945022288261516
Boosted Decision Tree insample query time: 0.04889845848083496
Out of sample accuracy for Boosted Decision Tree: 0.7990909090909091
Out of sample precision for Boosted Decision Tree: 0.515625
Out of sample recall for Boosted Decision Tree: 0.6685962373371924
Boosted Decision Tree out of sample query time: 0.02789759635925293
END OF ITERATION
----------------------------------------------------------------------------------
K NEAREST NEIGHBORS RESULTS
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,
                     weights='uniform')
Cross Validation Results: [0.21543378 0.21543378 0.07353816 0.10546824 0.01782624 0.05794078
 0.00520115 0.02228554]
Training Set 1:
KNN training time: 0.0009660720825195312
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.002025127410888672
Out of sample accuracy for KNN: 0.7096969696969697
Out of sample precision for KNN: 0.28976377952755905
Out of sample recall for KNN: 0.2662807525325615
KNN out of sample query time: 0.055850982666015625
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
KNN training time: 0.0009663105010986328
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.020975351333618164
Out of sample accuracy for KNN: 0.7509090909090909
Out of sample precision for KNN: 0.3899159663865546
Out of sample recall for KNN: 0.3357452966714906
KNN out of sample query time: 0.08174967765808105
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
KNN training time: 0.0019948482513427734
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.05286002159118652
Out of sample accuracy for KNN: 0.7642424242424243
Out of sample precision for KNN: 0.4238178633975482
Out of sample recall for KNN: 0.35021707670043417
KNN out of sample query time: 0.10468459129333496
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
KNN training time: 0.004988670349121094
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.12266993522644043
Out of sample accuracy for KNN: 0.7775757575757576
Out of sample precision for KNN: 0.4620811287477954
Out of sample recall for KNN: 0.3791606367583213
KNN out of sample query time: 0.12865376472473145
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
KNN training time: 0.005014657974243164
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.18550753593444824
Out of sample accuracy for KNN: 0.7836363636363637
Out of sample precision for KNN: 0.4799301919720768
Out of sample recall for KNN: 0.3979739507959479
KNN out of sample query time: 0.1415269374847412
END OF ITERATION
----------------------------------------------------------------------------------
SUPPORT VECTOR MACHINE RESULTS
Best Classifier Chosen: LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
Cross Validation Results: [0.42783902 0.42783902 0.42783902 0.42783902 0.42783902 0.42783902]
Training Set 1:
SVC training time: 0.0019931793212890625
Best Classifier Chosen: LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
In sample accuracy for SVC: 0.73
In sample precision for SVC: 0.35135135135135137
In sample recall for SVC: 0.8125
SVC insample query time: 0.0009984970092773438
Out of sample accuracy for SVC: 0.6693939393939394
Out of sample precision for SVC: 0.32964224872231684
Out of sample recall for SVC: 0.5600578871201157
SVC out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
SVC training time: 0.004986763000488281
Best Classifier Chosen: LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
In sample accuracy for SVC: 0.74
In sample precision for SVC: 0.42857142857142855
In sample recall for SVC: 0.75
SVC insample query time: 0.000997304916381836
Out of sample accuracy for SVC: 0.7260606060606061
Out of sample precision for SVC: 0.40583554376657827
Out of sample recall for SVC: 0.6642547033285094
SVC out of sample query time: 0.0009975433349609375
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
SVC training time: 0.006981372833251953
Best Classifier Chosen: LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
In sample accuracy for SVC: 0.7144
In sample precision for SVC: 0.3708609271523179
In sample recall for SVC: 0.7
SVC insample query time: 0.000997781753540039
Out of sample accuracy for SVC: 0.7178787878787879
Out of sample precision for SVC: 0.3941798941798942
Out of sample recall for SVC: 0.6468885672937771
SVC out of sample query time: 0.0009975433349609375
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
SVC training time: 0.01296544075012207
Best Classifier Chosen: LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
In sample accuracy for SVC: 0.718
In sample precision for SVC: 0.389428263214671
In sample recall for SVC: 0.722
SVC insample query time: 0.0
Out of sample accuracy for SVC: 0.7260606060606061
Out of sample precision for SVC: 0.40431266846361186
Out of sample recall for SVC: 0.6512301013024602
SVC out of sample query time: 0.0009975433349609375
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
SVC training time: 0.017950773239135742
Best Classifier Chosen: LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
In sample accuracy for SVC: 0.7192537313432836
In sample precision for SVC: 0.39174423310400647
In sample recall for SVC: 0.7191679049034175
SVC insample query time: 0.0009970664978027344
Out of sample accuracy for SVC: 0.7275757575757575
Out of sample precision for SVC: 0.40747330960854095
Out of sample recall for SVC: 0.662807525325615
SVC out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
NEURAL NETWORK RESULTS
Training Set 1:
NN training time: 4.776164531707764
In sample accuracy for nn: 0.86
In sample precision for NN: 0.8653846153846154
In sample recall for NN: 0.8653846153846154
NN insample query time: 0.0
Out of sample accuracy for NN: 0.6606060606060606
Out of sample precision for NN: 0.3198992443324937
Out of sample recall for NN: 0.5513748191027497
SVC out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
NN training time: 8.146790981292725
In sample accuracy for nn: 0.694
In sample precision for NN: 0.7151394422310757
In sample recall for NN: 0.6877394636015326
NN insample query time: 0.0
Out of sample accuracy for NN: 0.6645454545454546
Out of sample precision for NN: 0.33570300157977884
Out of sample recall for NN: 0.6150506512301013
SVC out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
NN training time: 13.184001922607422
In sample accuracy for nn: 0.7216
In sample precision for NN: 0.7198697068403909
In sample recall for NN: 0.7152103559870551
NN insample query time: 0.0009982585906982422
Out of sample accuracy for NN: 0.7403030303030304
Out of sample precision for NN: 0.42343173431734316
Out of sample recall for NN: 0.6642547033285094
SVC out of sample query time: 0.000997304916381836
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
NN training time: 17.83672261238098
In sample accuracy for nn: 0.71
In sample precision for NN: 0.7116862110796603
In sample recall for NN: 0.7048458149779736
NN insample query time: 0.0
Out of sample accuracy for NN: 0.7193939393939394
Out of sample precision for NN: 0.39737991266375544
Out of sample recall for NN: 0.658465991316932
SVC out of sample query time: 0.000997304916381836
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
NN training time: 35.19891953468323
In sample accuracy for nn: 0.6864026895778856
In sample precision for NN: 0.6858472998137802
In sample recall for NN: 0.6878968995143818
NN insample query time: 0.0009968280792236328
Out of sample accuracy for NN: 0.6863636363636364
Out of sample precision for NN: 0.3615136876006441
Out of sample recall for NN: 0.6497829232995659
SVC out of sample query time: 0.0009975433349609375
END OF ITERATION
----------------------------------------------------------------------------------
