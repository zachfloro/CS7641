DECISION TREE RESULTS
Best Classifier Chosen: DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
                       max_depth=5, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=20,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
Cross Validation Results: [0.67013096 0.67013096 0.73330646 0.73553583 0.6812998  0.6916977 ]
Training Set 1:
Decision Tree training time: 0.001003265380859375
In sample accuracy for Decision Tree: 0.77
In sample precision for Decision Tree: 0.41025641025641024
In sample recall for Decision Tree: 1.0
Decision Tree insample query time: 0.0
Out of sample accuracy for Decision Tree: 0.62
Out of sample precision for Decision Tree: 0.2698282910874898
Out of sample recall for Decision Tree: 0.47756874095513746
Decision Tree out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
Decision Tree training time: 0.002991199493408203
In sample accuracy for Decision Tree: 0.739
In sample precision for Decision Tree: 0.4373522458628842
In sample recall for Decision Tree: 0.8894230769230769
Decision Tree insample query time: 0.0
Out of sample accuracy for Decision Tree: 0.6793939393939394
Out of sample precision for Decision Tree: 0.3647752394988946
Out of sample recall for Decision Tree: 0.7163531114327062
Decision Tree out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
Decision Tree training time: 0.005983591079711914
In sample accuracy for Decision Tree: 0.7948
In sample precision for Decision Tree: 0.4775510204081633
In sample recall for Decision Tree: 0.73125
Decision Tree insample query time: 0.0
Out of sample accuracy for Decision Tree: 0.7887878787878788
Out of sample precision for Decision Tree: 0.49668141592920356
Out of sample recall for Decision Tree: 0.6497829232995659
Decision Tree out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
Decision Tree training time: 0.0109710693359375
In sample accuracy for Decision Tree: 0.7936
In sample precision for Decision Tree: 0.48933333333333334
In sample recall for Decision Tree: 0.734
Decision Tree insample query time: 0.000997781753540039
Out of sample accuracy for Decision Tree: 0.7821212121212121
Out of sample precision for Decision Tree: 0.48544698544698545
Out of sample recall for Decision Tree: 0.6758321273516642
Decision Tree out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
Decision Tree training time: 0.013933897018432617
In sample accuracy for Decision Tree: 0.7950746268656717
In sample precision for Decision Tree: 0.49327354260089684
In sample recall for Decision Tree: 0.7355126300148589
Decision Tree insample query time: 0.0009970664978027344
Out of sample accuracy for Decision Tree: 0.7881818181818182
Out of sample precision for Decision Tree: 0.49580712788259956
Out of sample recall for Decision Tree: 0.6845151953690304
Decision Tree out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
DECISION TREE W/ BOOSTING RESULTS
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight='balanced',
                                                         criterion='entropy',
                                                         max_depth=10,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=30,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=0.001, n_estimators=50, random_state=13)
Cross Validation Results: [0.36033955 0.45617481 0.55201942 0.39450228 0.47919174 0.60774128
 0.40193336 0.48885938 0.61591859 0.41233677 0.407867   0.5037161
 0.34545096 0.3877938  0.54160785 0.37221127 0.39152285 0.56166948
 0.38336857 0.39374174 0.50222967 0.3506373  0.40341099 0.53937957
 0.3766667  0.40044034 0.56241297]
Training Set 1:
Boosted Decision Tree training time: 0.04086017608642578
In sample accuracy for Boosted Decision Tree: 0.89
In sample precision for Boosted Decision Tree: 0.5925925925925926
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.0039899349212646484
Out of sample accuracy for Boosted Decision Tree: 0.7366666666666667
Out of sample precision for Boosted Decision Tree: 0.34494773519163763
Out of sample recall for Boosted Decision Tree: 0.2865412445730825
Boosted Decision Tree out of sample query time: 0.020946025848388672
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
Boosted Decision Tree training time: 0.24733734130859375
In sample accuracy for Boosted Decision Tree: 0.926
In sample precision for Boosted Decision Tree: 0.7481481481481481
In sample recall for Boosted Decision Tree: 0.9711538461538461
Boosted Decision Tree insample query time: 0.010970354080200195
Out of sample accuracy for Boosted Decision Tree: 0.7881818181818182
Out of sample precision for Boosted Decision Tree: 0.49493670886075947
Out of sample recall for Boosted Decision Tree: 0.5658465991316932
Boosted Decision Tree out of sample query time: 0.024933576583862305
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
Boosted Decision Tree training time: 0.4916853904724121
In sample accuracy for Boosted Decision Tree: 0.9144
In sample precision for Boosted Decision Tree: 0.7071651090342679
In sample recall for Boosted Decision Tree: 0.9458333333333333
Boosted Decision Tree insample query time: 0.020973682403564453
Out of sample accuracy for Boosted Decision Tree: 0.8133333333333334
Out of sample precision for Boosted Decision Tree: 0.5490196078431373
Out of sample recall for Boosted Decision Tree: 0.6078147612156295
Boosted Decision Tree out of sample query time: 0.026927947998046875
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
Boosted Decision Tree training time: 0.96071457862854
In sample accuracy for Boosted Decision Tree: 0.9176
In sample precision for Boosted Decision Tree: 0.7340764331210191
In sample recall for Boosted Decision Tree: 0.922
Boosted Decision Tree insample query time: 0.03690147399902344
Out of sample accuracy for Boosted Decision Tree: 0.8172727272727273
Out of sample precision for Boosted Decision Tree: 0.5591397849462365
Out of sample recall for Boosted Decision Tree: 0.6020260492040521
Boosted Decision Tree out of sample query time: 0.026928186416625977
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
Boosted Decision Tree training time: 1.300520896911621
In sample accuracy for Boosted Decision Tree: 0.8719402985074627
In sample precision for Boosted Decision Tree: 0.6270833333333333
In sample recall for Boosted Decision Tree: 0.8945022288261516
Boosted Decision Tree insample query time: 0.05086374282836914
Out of sample accuracy for Boosted Decision Tree: 0.7990909090909091
Out of sample precision for Boosted Decision Tree: 0.515625
Out of sample recall for Boosted Decision Tree: 0.6685962373371924
Boosted Decision Tree out of sample query time: 0.027925491333007812
END OF ITERATION
----------------------------------------------------------------------------------
K NEAREST NEIGHBORS RESULTS
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,
                     weights='uniform')
Cross Validation Results: [0.21543378 0.21543378 0.07353816 0.10546824 0.01782624 0.05794078
 0.00520115 0.02228554]
Training Set 1:
KNN training time: 0.0009975433349609375
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.001994609832763672
Out of sample accuracy for KNN: 0.7096969696969697
Out of sample precision for KNN: 0.28976377952755905
Out of sample recall for KNN: 0.2662807525325615
KNN out of sample query time: 0.05884289741516113
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
KNN training time: 0.0019948482513427734
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.03690075874328613
Out of sample accuracy for KNN: 0.7509090909090909
Out of sample precision for KNN: 0.3899159663865546
Out of sample recall for KNN: 0.3357452966714906
KNN out of sample query time: 0.10571670532226562
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
KNN training time: 0.002991914749145508
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.052858829498291016
Out of sample accuracy for KNN: 0.7642424242424243
Out of sample precision for KNN: 0.4238178633975482
Out of sample recall for KNN: 0.35021707670043417
KNN out of sample query time: 0.1036992073059082
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
KNN training time: 0.005013227462768555
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.1186830997467041
Out of sample accuracy for KNN: 0.7775757575757576
Out of sample precision for KNN: 0.4620811287477954
Out of sample recall for KNN: 0.3791606367583213
KNN out of sample query time: 0.1256694793701172
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
KNN training time: 0.005974531173706055
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.18052887916564941
Out of sample accuracy for KNN: 0.7836363636363637
Out of sample precision for KNN: 0.4799301919720768
Out of sample recall for KNN: 0.3979739507959479
KNN out of sample query time: 0.140655517578125
END OF ITERATION
----------------------------------------------------------------------------------
SUPPORT VECTOR MACHINE RESULTS
Best Classifier Chosen: LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
Cross Validation Results: [0.42783902 0.42783902 0.42783902 0.42783902 0.42783902 0.42783902]
Training Set 1:
SVC training time: 0.0019941329956054688
Best Classifier Chosen: LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
In sample accuracy for SVC: 0.73
In sample precision for SVC: 0.35135135135135137
In sample recall for SVC: 0.8125
SVC insample query time: 0.0
Out of sample accuracy for SVC: 0.6693939393939394
Out of sample precision for SVC: 0.32964224872231684
Out of sample recall for SVC: 0.5600578871201157
SVC out of sample query time: 0.0009996891021728516
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
SVC training time: 0.003989219665527344
Best Classifier Chosen: LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
In sample accuracy for SVC: 0.74
In sample precision for SVC: 0.42857142857142855
In sample recall for SVC: 0.75
SVC insample query time: 0.0
Out of sample accuracy for SVC: 0.7260606060606061
Out of sample precision for SVC: 0.40583554376657827
Out of sample recall for SVC: 0.6642547033285094
SVC out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
SVC training time: 0.006980180740356445
Best Classifier Chosen: LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
In sample accuracy for SVC: 0.7144
In sample precision for SVC: 0.3708609271523179
In sample recall for SVC: 0.7
SVC insample query time: 0.000997304916381836
Out of sample accuracy for SVC: 0.7178787878787879
Out of sample precision for SVC: 0.3941798941798942
Out of sample recall for SVC: 0.6468885672937771
SVC out of sample query time: 0.000997304916381836
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
SVC training time: 0.018949270248413086
Best Classifier Chosen: LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
In sample accuracy for SVC: 0.718
In sample precision for SVC: 0.389428263214671
In sample recall for SVC: 0.722
SVC insample query time: 0.000997304916381836
Out of sample accuracy for SVC: 0.7260606060606061
Out of sample precision for SVC: 0.40431266846361186
Out of sample recall for SVC: 0.6512301013024602
SVC out of sample query time: 0.0009970664978027344
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
SVC training time: 0.017981529235839844
Best Classifier Chosen: LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
In sample accuracy for SVC: 0.7192537313432836
In sample precision for SVC: 0.39174423310400647
In sample recall for SVC: 0.7191679049034175
SVC insample query time: 0.0009965896606445312
Out of sample accuracy for SVC: 0.7275757575757575
Out of sample precision for SVC: 0.40747330960854095
Out of sample recall for SVC: 0.662807525325615
SVC out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
NEURAL NETWORK RESULTS
Training Set 1:
NN training time: 4.578272581100464
In sample accuracy for nn: 0.87
In sample precision for NN: 0.8571428571428571
In sample recall for NN: 0.875
NN insample query time: 0.0
Out of sample accuracy for NN: 0.7018181818181818
Out of sample precision for NN: 0.3595397890699904
Out of sample recall for NN: 0.5426917510853835
SVC out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
NN training time: 7.988239049911499
In sample accuracy for nn: 0.57
In sample precision for NN: 0.5578144853875476
In sample recall for NN: 0.8426103646833013
NN insample query time: 0.0
Out of sample accuracy for NN: 0.41484848484848486
Out of sample precision for NN: 0.24652493867538838
Out of sample recall for NN: 0.8726483357452967
SVC out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
NN training time: 13.702928304672241
In sample accuracy for nn: 0.7248
In sample precision for NN: 0.7207514944491887
In sample recall for NN: 0.700414937759336
NN insample query time: 0.0009970664978027344
Out of sample accuracy for NN: 0.723030303030303
Out of sample precision for NN: 0.3972350230414747
Out of sample recall for NN: 0.6237337192474675
SVC out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
NN training time: 19.55929446220398
In sample accuracy for nn: 0.7166
In sample precision for NN: 0.7174979558462796
In sample recall for NN: 0.7073760580411125
NN insample query time: 0.0009968280792236328
Out of sample accuracy for NN: 0.7227272727272728
Out of sample precision for NN: 0.3994614003590664
Out of sample recall for NN: 0.6439942112879884
SVC out of sample query time: 0.0009980201721191406
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
NN training time: 36.14705491065979
In sample accuracy for nn: 0.710683601045947
In sample precision for NN: 0.7117912129177619
In sample recall for NN: 0.7080687336570788
NN insample query time: 0.001994609832763672
Out of sample accuracy for NN: 0.7172727272727273
Out of sample precision for NN: 0.39404553415061294
Out of sample recall for NN: 0.6512301013024602
SVC out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
