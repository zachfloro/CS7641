DECISION TREE RESULTS
Training Set 1:
Decision Tree training time: 0.2822904586791992
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 0.74
In sample precision for Decision Tree: 0.7192982456140351
In sample recall for Decision Tree: 0.803921568627451
Decision Tree insample query time: 0.0
Out of sample accuracy for Decision Tree: 0.6106060606060606
Out of sample precision for Decision Tree: 0.3177914110429448
Out of sample recall for Decision Tree: 0.7496382054992764
Decision Tree out of sample query time: 0.000997304916381836
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
Decision Tree training time: 0.3700106143951416
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 1.0
In sample precision for Decision Tree: 1.0
In sample recall for Decision Tree: 1.0
Decision Tree insample query time: 0.0009980201721191406
Out of sample accuracy for Decision Tree: 0.713030303030303
Out of sample precision for Decision Tree: 0.3904109589041096
Out of sample recall for Decision Tree: 0.6599131693198264
Decision Tree out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
Decision Tree training time: 0.6103677749633789
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 1.0
In sample precision for Decision Tree: 1.0
In sample recall for Decision Tree: 1.0
Decision Tree insample query time: 0.000997781753540039
Out of sample accuracy for Decision Tree: 0.743030303030303
Out of sample precision for Decision Tree: 0.4247363374880153
Out of sample recall for Decision Tree: 0.6410998552821997
Decision Tree out of sample query time: 0.000997304916381836
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
Decision Tree training time: 0.9514567852020264
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 1.0
In sample precision for Decision Tree: 1.0
In sample recall for Decision Tree: 1.0
Decision Tree insample query time: 0.000997781753540039
Out of sample accuracy for Decision Tree: 0.7633333333333333
Out of sample precision for Decision Tree: 0.4489795918367347
Out of sample recall for Decision Tree: 0.573082489146165
Decision Tree out of sample query time: 0.000997304916381836
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
Decision Tree training time: 1.7034571170806885
Best Classifier Chosen: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=13, splitter='best')
In sample accuracy for Decision Tree: 1.0
In sample precision for Decision Tree: 1.0
In sample recall for Decision Tree: 1.0
Decision Tree insample query time: 0.0019953250885009766
Out of sample accuracy for Decision Tree: 0.8009090909090909
Out of sample precision for Decision Tree: 0.5266457680250783
Out of sample recall for Decision Tree: 0.48625180897250364
Decision Tree out of sample query time: 0.000997781753540039
END OF ITERATION
----------------------------------------------------------------------------------
DECISION TREE W/ BOOSTING RESULTS
Training Set 1:
Boosted Decision Tree training time: 1.732414960861206
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=5,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=10,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.00498652458190918
Out of sample accuracy for Boosted Decision Tree: 0.673030303030303
Out of sample precision for Boosted Decision Tree: 0.35714285714285715
Out of sample recall for Boosted Decision Tree: 0.7018813314037626
Boosted Decision Tree out of sample query time: 0.021941184997558594
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
Boosted Decision Tree training time: 4.797008275985718
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=25,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=5,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.01296544075012207
Out of sample accuracy for Boosted Decision Tree: 0.7830303030303031
Out of sample precision for Boosted Decision Tree: 0.48639825897714906
Out of sample recall for Boosted Decision Tree: 0.6468885672937771
Boosted Decision Tree out of sample query time: 0.028922557830810547
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
Boosted Decision Tree training time: 10.00675654411316
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=25,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=5,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.022933244705200195
Out of sample accuracy for Boosted Decision Tree: 0.8021212121212121
Out of sample precision for Boosted Decision Tree: 0.5241116751269036
Out of sample recall for Boosted Decision Tree: 0.597684515195369
Boosted Decision Tree out of sample query time: 0.02892303466796875
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
Boosted Decision Tree training time: 19.05711841583252
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=50,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=5,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.04587745666503906
Out of sample accuracy for Boosted Decision Tree: 0.8275757575757576
Out of sample precision for Boosted Decision Tree: 0.6055363321799307
Out of sample recall for Boosted Decision Tree: 0.5065123010130246
Boosted Decision Tree out of sample query time: 0.03091740608215332
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
Boosted Decision Tree training time: 39.244834899902344
Best Classifier Chosen: AdaBoostClassifier(algorithm='SAMME.R',
                   base_estimator=DecisionTreeClassifier(class_weight=None,
                                                         criterion='gini',
                                                         max_depth=50,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_impurity_split=None,
                                                         min_samples_leaf=1,
                                                         min_samples_split=5,
                                                         min_weight_fraction_leaf=0.0,
                                                         presort=False,
                                                         random_state=13,
                                                         splitter='best'),
                   learning_rate=1.0, n_estimators=50, random_state=13)
In sample accuracy for Boosted Decision Tree: 1.0
In sample precision for Boosted Decision Tree: 1.0
In sample recall for Boosted Decision Tree: 1.0
Boosted Decision Tree insample query time: 0.08876204490661621
Out of sample accuracy for Boosted Decision Tree: 0.8390909090909091
Out of sample precision for Boosted Decision Tree: 0.7409638554216867
Out of sample recall for Boosted Decision Tree: 0.35600578871201155
Boosted Decision Tree out of sample query time: 0.031914710998535156
END OF ITERATION
----------------------------------------------------------------------------------
K NEAREST NEIGHBORS RESULTS
Training Set 1:
KNN training time: 0.06778883934020996
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,
                     weights='uniform')
In sample accuracy for KNN: 0.7
In sample precision for KNN: 0.7142857142857143
In sample recall for KNN: 0.6862745098039216
KNN insample query time: 0.002025604248046875
Out of sample accuracy for KNN: 0.6493939393939394
Out of sample precision for KNN: 0.29632867132867136
Out of sample recall for KNN: 0.4905933429811867
KNN out of sample query time: 0.06283259391784668
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
KNN training time: 0.21559906005859375
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,
                     weights='distance')
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.013960123062133789
Out of sample accuracy for KNN: 0.6833333333333333
Out of sample precision for KNN: 0.35225375626043404
Out of sample recall for KNN: 0.6107091172214182
KNN out of sample query time: 0.044877052307128906
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
KNN training time: 0.5954391956329346
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,
                     weights='uniform')
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.05784296989440918
Out of sample accuracy for KNN: 0.7124242424242424
Out of sample precision for KNN: 0.37572254335260113
Out of sample recall for KNN: 0.5643994211287988
KNN out of sample query time: 0.09674406051635742
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
KNN training time: 1.7504918575286865
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,
                     weights='uniform')
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.12566089630126953
Out of sample accuracy for KNN: 0.7396969696969697
Out of sample precision for KNN: 0.39526184538653364
Out of sample recall for KNN: 0.45875542691751087
KNN out of sample query time: 0.1356353759765625
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
KNN training time: 5.055561304092407
Best Classifier Chosen: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,
                     weights='uniform')
In sample accuracy for KNN: 1.0
In sample precision for KNN: 1.0
In sample recall for KNN: 1.0
KNN insample query time: 0.34010744094848633
Out of sample accuracy for KNN: 0.7863636363636364
Out of sample precision for KNN: 0.4875886524822695
Out of sample recall for KNN: 0.3979739507959479
KNN out of sample query time: 0.1825118064880371
END OF ITERATION
----------------------------------------------------------------------------------
SUPPORT VECTOR MACHINE RESULTS
Training Set 1:
SVC training time: 0.04886889457702637
Best Classifier Chosen: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
In sample accuracy for SVC: 0.66
In sample precision for SVC: 0.717948717948718
In sample recall for SVC: 0.5490196078431373
SVC insample query time: 0.0009975433349609375
Out of sample accuracy for SVC: 0.6909090909090909
Out of sample precision for SVC: 0.32518597236981933
Out of sample recall for SVC: 0.44283646888567296
SVC out of sample query time: 0.0009961128234863281
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 2:
SVC training time: 0.14960026741027832
Best Classifier Chosen: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=13, tol=0.0001,
          verbose=0)
In sample accuracy for SVC: 0.712
In sample precision for SVC: 0.7182795698924731
In sample recall for SVC: 0.6802443991853361
SVC insample query time: 0.0009984970092773438
Out of sample accuracy for SVC: 0.7384848484848485
Out of sample precision for SVC: 0.41650485436893203
Out of sample recall for SVC: 0.6208393632416788
SVC out of sample query time: 0.0009980201721191406
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 3:
SVC training time: 0.2682831287384033
Best Classifier Chosen: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
In sample accuracy for SVC: 0.7236
In sample precision for SVC: 0.7280550774526678
In sample recall for SVC: 0.6928746928746928
SVC insample query time: 0.0
Out of sample accuracy for SVC: 0.73
Out of sample precision for SVC: 0.4075785582255083
Out of sample recall for SVC: 0.638205499276411
SVC out of sample query time: 0.0
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 4:
SVC training time: 0.5974030494689941
Best Classifier Chosen: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
In sample accuracy for SVC: 0.7158
In sample precision for SVC: 0.7188485804416404
In sample recall for SVC: 0.7202686685104702
SVC insample query time: 0.0009982585906982422
Out of sample accuracy for SVC: 0.7284848484848485
Out of sample precision for SVC: 0.4074074074074074
Out of sample recall for SVC: 0.6526772793053546
SVC out of sample query time: 0.000997781753540039
END OF ITERATION
----------------------------------------------------------------------------------
Training Set 5:
SVC training time: 1.0821187496185303
Best Classifier Chosen: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
          penalty='l2', random_state=13, tol=0.0001, verbose=0)
In sample accuracy for SVC: 0.7167538289129622
In sample precision for SVC: 0.71875589066918
In sample recall for SVC: 0.712177810982443
SVC insample query time: 0.0009865760803222656
Out of sample accuracy for SVC: 0.7275757575757575
Out of sample precision for SVC: 0.40714285714285714
Out of sample recall for SVC: 0.6599131693198264
SVC out of sample query time: 0.0009975433349609375
END OF ITERATION
----------------------------------------------------------------------------------
NEURAL NETWORK RESULTS
Training Set 1:
NN training time: 4.692512273788452
